{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inverted_Indexing",
      "provenance": [],
      "authorship_tag": "ABX9TyP2ykFiAQaiMBPCnJcT+Yc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naveen1331/Inverted_Indexing/blob/main/Inverted_Indexing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vd5CGoPaCCu",
        "outputId": "20f62351-204e-4f17-af59-af0a5ec348af"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg2PGhu3aQcX",
        "outputId": "9ae6eb18-ee49-4447-8938-2e3d4c80f03c"
      },
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shMH3gbpZWHB",
        "outputId": "77f17b06-0b37-4c0a-8b32-7be3ca4cf30e"
      },
      "source": [
        "array = [] \r\n",
        "dict = {} \r\n",
        "for j in range(10):\r\n",
        "    # this will open the file \r\n",
        "    f=\"file\"+str(j)+'.txt'\r\n",
        "    file = open(f, encoding='utf8') \r\n",
        "    read = file.read() \r\n",
        "    file.seek(0) \r\n",
        "    read \r\n",
        "\r\n",
        "    # to obtain the \r\n",
        "    # number of lines \r\n",
        "    # in file \r\n",
        "    line = 1\r\n",
        "    for word in read: \r\n",
        "        if word == '\\n': \r\n",
        "            line += 1\r\n",
        "    print(\"Number of lines in file is: \", line) \r\n",
        "\r\n",
        "    # create a list to \r\n",
        "    # store each line as \r\n",
        "    # an element of list \r\n",
        "    \r\n",
        "    for i in range(line): \r\n",
        "        array.append(file.readline()) \r\n",
        "\r\n",
        "    array \r\n",
        "\r\n",
        "\r\n",
        "    punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\r\n",
        "    for ele in read:   \r\n",
        "        if ele in punc:   \r\n",
        "            read = read.replace(ele, \" \")   \r\n",
        "\r\n",
        "    read \r\n",
        "\r\n",
        "    # to maintain uniformity \r\n",
        "    read=read.lower()                     \r\n",
        "    read\r\n",
        "\r\n",
        "\r\n",
        "    from nltk.tokenize import word_tokenize \r\n",
        "    import nltk \r\n",
        "    from nltk.corpus import stopwords \r\n",
        "\r\n",
        "    for i in range(1): \r\n",
        "        # this will convert \r\n",
        "        # the word into tokens \r\n",
        "        text_tokens = word_tokenize(read) \r\n",
        "\r\n",
        "    tokens_without_sw = [ \r\n",
        "        word for word in text_tokens if not word in stopwords.words()] \r\n",
        "\r\n",
        "    print(tokens_without_sw) \r\n",
        "\r\n",
        "\r\n",
        "    for i in range(line): \r\n",
        "        check = array[i].lower() \r\n",
        "        for item in tokens_without_sw: \r\n",
        "\r\n",
        "            if item in check: \r\n",
        "                if item not in dict: \r\n",
        "                    dict[item] = [] \r\n",
        "\r\n",
        "                if item in dict: \r\n",
        "                    dict[item].append(j+1) \r\n",
        "\r\n",
        "dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines in file is:  1\n",
            "['january', '20', '2014', 'subodh', 'varma', 'reporting', 'economic', 'times', 'indicated', 'wikipedia', 'growth', 'stalled', 'lost', 'nearly', 'ten', 'percent', 'page', 'views', 'last', 'year', 'decline', 'two', 'billion', 'december', '2012', 'december', '2013', 'popular', 'versions', 'leading', 'slide', 'page', 'views', 'english', 'wikipedia', 'declined', 'twelve', 'percent', 'german', 'version', 'slid', '17', 'percent', 'japanese', 'version', 'lost', 'nine', 'percent']\n",
            "Number of lines in file is:  1\n",
            "['varma', 'added', 'wikipedia', 'managers', 'think', 'could', 'due', 'errors', 'counting', 'experts', 'feel', 'google', 'knowledge', 'graphs', 'project', 'launched', 'last', 'year', 'may', 'gobbling', 'wikipedia', 'users', '53', 'contacted', 'matter', 'clay', 'shirky', 'associate', 'professor', 'new', 'york', 'university', 'fellow', 'harvard', 'berkman', 'klein', 'center', 'internet', 'society', 'indicated', 'suspected', 'much', 'page', 'view', 'decline', 'due', 'knowledge', 'graphs', 'stating', 'get', 'question', 'answered', 'search', 'page', 'need', 'click', '53', 'december', '2016', 'wikipedia', 'ranked', 'fifth', 'popular', 'websites', 'globally']\n",
            "Number of lines in file is:  1\n",
            "['january', '2013', '274301', 'wikipedia', 'asteroid', 'named', 'wikipedia', 'october', '2014', 'wikipedia', 'honored', 'wikipedia', 'monument', 'july', '2015', '106', '7', '473', '700', 'page', 'volumes', 'wikipedia', 'became', 'available', 'print', 'wikipedia', 'april', '2019', 'israeli', 'lunar', 'lander', 'beresheet', 'crash', 'landed', 'surface', 'moon', 'carrying', 'copy', 'nearly', 'english', 'wikipedia', 'engraved', 'thin', 'nickel', 'plates', 'experts', 'say', 'plates', 'likely', 'survived', 'crash']\n",
            "Number of lines in file is:  1\n",
            "['unlike', 'traditional', 'encyclopedias', 'wikipedia', 'follows', 'procrastination', 'principle', 'note', '3', 'regarding', 'security', 'content', '60', 'started', 'almost', 'entirely', 'openâ€”anyone', 'could', 'create', 'articles', 'wikipedia', 'article', 'could', 'edited', 'reader', 'even', 'wikipedia', 'account', 'modifications', 'articles', 'would', 'published', 'immediately', 'result', 'article', 'could', 'contain', 'inaccuracies', 'errors', 'ideological', 'biases', 'nonsensical', 'irrelevant', 'text']\n",
            "Number of lines in file is:  1\n",
            "['due', 'increasing', 'popularity', 'wikipedia', 'editions', 'including', 'english', 'version', 'introduced', 'editing', 'restrictions', 'certain', 'cases', 'instance', 'english', 'wikipedia', 'language', 'editions', 'registered', 'users', 'may', 'create', 'new', 'article', '61', 'english', 'wikipedia', 'among', 'others', 'particularly', 'controversial', 'sensitive', 'vandalism', 'prone', 'pages', 'protected', 'varying', 'degrees']\n",
            "Number of lines in file is:  1\n",
            "['although', 'changes', 'systematically', 'reviewed', 'software', 'powers', 'wikipedia', 'provides', 'tools', 'allowing', 'anyone', 'review', 'changes', 'made', 'others', 'history', 'page', 'article', 'links', 'revision', 'note', '4', '70', 'articles', 'anyone', 'undo', 'others', 'changes', 'clicking', 'link', 'article', 'history', 'page', 'anyone', 'view', 'latest', 'changes', 'articles', 'anyone', 'may', 'maintain', 'watchlist', 'articles', 'interest', 'notified', 'changes', 'new', 'pages', 'patrol', 'process', 'whereby', 'newly', 'created', 'articles', 'checked', 'obvious', 'problems']\n",
            "Number of lines in file is:  1\n",
            "['change', 'edit', 'manipulates', 'content', 'way', 'purposefully', 'compromises', 'integrity', 'wikipedia', 'considered', 'vandalism', 'common', 'obvious', 'types', 'vandalism', 'include', 'additions', 'obscenities', 'crude', 'humor', 'vandalism', 'include', 'advertising', 'types', 'spam', '73', 'sometimes', 'editors', 'commit', 'vandalism', 'removing', 'content', 'entirely', 'blanking', 'given', 'page', 'less', 'common', 'types', 'vandalism']\n",
            "Number of lines in file is:  1\n",
            "['deliberate', 'addition', 'plausible', 'false', 'information', 'article', 'difficult', 'detect', 'vandals', 'introduce', 'irrelevant', 'formatting', 'modify', 'page', 'semantics', 'page', 'title', 'categorization', 'manipulate', 'underlying', 'code', 'article', 'use', 'images', 'disruptively']\n",
            "Number of lines in file is:  1\n",
            "['seigenthaler', 'biography', 'incident', 'anonymous', 'editor', 'introduced', 'false', 'information', 'biography', 'american', 'political', 'figure', 'john', 'seigenthaler', 'may', '2005', 'seigenthaler', 'falsely', 'presented', 'suspect', 'assassination', 'john', 'f', 'kennedy']\n",
            "Number of lines in file is:  1\n",
            "['article', 'remained', 'uncorrected', 'four', 'months', '77', 'seigenthaler', 'founding', 'editorial', 'director', 'usa', 'today', 'founder', 'freedom', 'forum', 'first', 'amendment', 'center', 'vanderbilt', 'university', 'called', 'wikipedia', 'co', 'founder', 'jimmy', 'wales', 'asked', 'whether', 'way', 'knowing', 'contributed', 'misinformation']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'17': [1],\n",
              " '20': [1],\n",
              " '2012': [1],\n",
              " '2013': [1, 3],\n",
              " '2014': [1, 3],\n",
              " '3': [4],\n",
              " '4': [6],\n",
              " '7': [3],\n",
              " 'billion': [1],\n",
              " 'co': [10],\n",
              " 'december': [1, 1, 2],\n",
              " 'decline': [1, 2],\n",
              " 'declined': [1],\n",
              " 'economic': [1],\n",
              " 'english': [1, 3, 5, 5, 5],\n",
              " 'f': [9],\n",
              " 'german': [1],\n",
              " 'growth': [1],\n",
              " 'indicated': [1, 2],\n",
              " 'january': [1, 3],\n",
              " 'japanese': [1],\n",
              " 'last': [1, 2],\n",
              " 'leading': [1],\n",
              " 'lost': [1, 1],\n",
              " 'nearly': [1, 3],\n",
              " 'nine': [1],\n",
              " 'page': [1, 1, 2, 2, 3, 6, 6, 7, 8, 8],\n",
              " 'percent': [1, 1, 1, 1],\n",
              " 'popular': [1, 2],\n",
              " 'reporting': [1],\n",
              " 'slid': [1],\n",
              " 'slide': [1],\n",
              " 'stalled': [1],\n",
              " 'subodh': [1],\n",
              " 'ten': [1],\n",
              " 'times': [1],\n",
              " 'twelve': [1],\n",
              " 'two': [1],\n",
              " 'varma': [1, 2],\n",
              " 'version': [1, 1, 5],\n",
              " 'versions': [1],\n",
              " 'view': [2, 6],\n",
              " 'views': [1, 1],\n",
              " 'wikipedia': [1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 7, 10],\n",
              " 'year': [1, 2]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKL6vElOZzb_"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}